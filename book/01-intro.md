# Introduction

## What is this book, and who's it for?

"You don't really understand something until you can explain it."

This book is my attempt to synthesize my understanding of how LLMs work. It's based on my reading of [_Build a Large Language Model (From Scratch)_ by Sebastian Raschka][Raschka].

The primary audience is me; but if you've found this and it helps you, all the better!

## Prerequisites

This book assumes basic math. The most advanced math topic is vectors and matrices, and even for those, the book includes an overview of what you need to know.

## Organization

The driving principle behind this book's organization is that you should be able to read it front-to-back. This means:

- The book assumes you don't know anything relating to LLMs (other than basic math).
- If you do know something, you can always skip past it; but you should never have to jump to an appendix and then back to where you were.

Human learning being the way it is, you may need to refer back to a section you've already read; "front-to-back" doesn't mean you shouldn't ever need to do this. But the book isn't organized around you having to jump around.

## Contributions

The source for this book is on [my GitHub][gh]. Please feel free to suggest corrections there, especially if I got something factually wrong. (If it's just a matter of wording or clarification, I may accept it, but no promises &mdash; sorry!)

[Raschka]: https://www.manning.com/books/build-a-large-language-model-from-scratch
[gh]: https://github.com/yshavit/llm-notes
